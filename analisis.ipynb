{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e53646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import oracledb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "\n",
    "# Crear carpeta de resultados\n",
    "CARPETA_RESULTADOS = \"resultado_analisis\"\n",
    "os.makedirs(CARPETA_RESULTADOS, exist_ok=True)\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "\n",
    "USER = \"\"\n",
    "PASSWORD = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c84ee982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1. CONEXIÓN A ORACLE DATABASE\n",
    "# ============================================\n",
    "def conectar_oracle():\n",
    "    \"\"\"Establece conexión con Oracle Database en OCI\"\"\"\n",
    "    try:\n",
    "        connection = oracledb.connect(\n",
    "            user=USER,  # o tu usuario\n",
    "            password=PASSWORD,\n",
    "            dsn=\"malackathon2025v2_high\",  # nombre del servicio del tnsnames.ora\n",
    "            config_dir=\"WALLET/\",\n",
    "            wallet_location=\"WALLET/\",\n",
    "            wallet_password=\"Malakathon@2025\"  # si configuraste una\n",
    "        )\n",
    "        return connection\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error de conexión: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "451feaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2. CARGAR DATOS\n",
    "# ============================================\n",
    "def cargar_datos(connection, query=\"SELECT * FROM SALUDMENTAL\"):\n",
    "    \"\"\"Carga datos desde Oracle a DataFrame de pandas\"\"\"\n",
    "    try:\n",
    "        df = pd.read_sql(query, connection)\n",
    "        print(f\"✓ Datos cargados: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error al cargar datos: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5413c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisis_descriptivo(df):\n",
    "    \"\"\"Análisis estadístico elemental de las variables\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"1. ANÁLISIS DESCRIPTIVO INICIAL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Información general\n",
    "    print(\"\\n--- INFORMACIÓN GENERAL ---\")\n",
    "    print(f\"Dimensiones: {df.shape[0]} filas × {df.shape[1]} columnas\")\n",
    "    print(f\"Memoria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Tipos de datos\n",
    "    print(\"\\n--- TIPOS DE DATOS ---\")\n",
    "    tipos_datos = df.dtypes.value_counts()\n",
    "    print(tipos_datos)\n",
    "    \n",
    "    # Clasificación de variables\n",
    "    numericas = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categoricas = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    fechas = df.select_dtypes(include=['datetime64']).columns.tolist()\n",
    "    \n",
    "    # Detectar columnas de fecha en formato object\n",
    "    for col in categoricas.copy():\n",
    "        try:\n",
    "            pd.to_datetime(df[col], errors='raise')\n",
    "            fechas.append(col)\n",
    "            categoricas.remove(col)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(f\"\\nVariables numéricas ({len(numericas)}): {numericas}\")\n",
    "    print(f\"Variables categóricas ({len(categoricas)}): {categoricas}\")\n",
    "    print(f\"Variables de fecha ({len(fechas)}): {fechas}\")\n",
    "    \n",
    "    # Valores nulos\n",
    "    print(\"\\n--- VALORES NULOS Y DESCONOCIDOS ---\")\n",
    "    nulos = df.isnull().sum()\n",
    "    porcentaje_nulos = (nulos / len(df) * 100).round(2)\n",
    "    \n",
    "    tabla_nulos = pd.DataFrame({\n",
    "        'Variable': nulos.index,\n",
    "        'Valores Nulos': nulos.values,\n",
    "        '% Nulos': porcentaje_nulos.values\n",
    "    })\n",
    "    tabla_nulos = tabla_nulos[tabla_nulos['Valores Nulos'] > 0].sort_values('Valores Nulos', ascending=False)\n",
    "    \n",
    "    if len(tabla_nulos) > 0:\n",
    "        print(tabla_nulos.to_string(index=False))\n",
    "    else:\n",
    "        print(\"✓ No hay valores nulos en el dataset\")\n",
    "    \n",
    "    # Estadísticas descriptivas para variables numéricas\n",
    "    if len(numericas) > 0:\n",
    "        print(\"\\n--- ESTADÍSTICAS DESCRIPTIVAS (Variables Numéricas) ---\")\n",
    "        print(df[numericas].describe().round(2))\n",
    "\n",
    "        # === NUEVO BLOQUE AÑADIDO ===\n",
    "        print(\"\\n--- MEDIA, VARIANZA Y DESVIACIÓN TÍPICA ---\")\n",
    "        resumen_estadistico = pd.DataFrame({\n",
    "            'Media': df[numericas].mean(),\n",
    "            'Varianza': df[numericas].var(),\n",
    "            'Desviación Típica': df[numericas].std()\n",
    "        }).round(2)\n",
    "\n",
    "    print(resumen_estadistico)\n",
    "    \n",
    "    # Guardar resultados dentro de la carpeta resultado_analisis\n",
    "    resumen_path = os.path.join(CARPETA_RESULTADOS, 'resumen_estadistico.csv')\n",
    "    resumen_estadistico.to_csv(resumen_path, index=True)\n",
    "    print(f\"✓ Resumen estadístico guardado: {resumen_path}\")\n",
    "\n",
    "    \n",
    "    # Frecuencias para variables categóricas\n",
    "    if len(categoricas) > 0:\n",
    "        print(\"\\n--- ANÁLISIS DE VARIABLES CATEGÓRICAS ---\")\n",
    "        for col in categoricas[:5]:  # Primeras 5 categóricas\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  Valores únicos: {df[col].nunique()}\")\n",
    "            print(f\"  Top 5 valores más frecuentes:\")\n",
    "            print(df[col].value_counts().head().to_string())\n",
    "    \n",
    "    return {\n",
    "        'numericas': numericas,\n",
    "        'categoricas': categoricas,\n",
    "        'fechas': fechas,\n",
    "        'nulos': tabla_nulos\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "629c7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_outliers(df, columnas_numericas):\n",
    "    \"\"\"Detecta outliers usando método IQR y Z-score\"\"\"\n",
    "    \n",
    "    print(\"\\n--- DETECCIÓN DE OUTLIERS ---\")\n",
    "    \n",
    "    outliers_info = {}\n",
    "    \n",
    "    for col in columnas_numericas:\n",
    "        # Método IQR\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        limite_inferior = Q1 - 1.5 * IQR\n",
    "        limite_superior = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers_iqr = df[(df[col] < limite_inferior) | (df[col] > limite_superior)]\n",
    "        \n",
    "        # Método Z-score (corregido)\n",
    "        data_sin_nulos = df[col].dropna()\n",
    "        if len(data_sin_nulos) > 0:\n",
    "            z_scores = np.abs(stats.zscore(data_sin_nulos))\n",
    "            outliers_z_mask = z_scores > 3\n",
    "            num_outliers_z = np.sum(outliers_z_mask)\n",
    "        else:\n",
    "            num_outliers_z = 0\n",
    "        \n",
    "        if len(outliers_iqr) > 0:\n",
    "            outliers_info[col] = {\n",
    "                'IQR': len(outliers_iqr),\n",
    "                'Z-score': num_outliers_z,\n",
    "                'porcentaje': round(len(outliers_iqr) / len(df) * 100, 2)\n",
    "            }\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  Outliers (IQR): {len(outliers_iqr)} ({outliers_info[col]['porcentaje']}%)\")\n",
    "            print(f\"  Outliers (Z-score > 3): {num_outliers_z}\")\n",
    "            print(f\"  Rango normal: [{limite_inferior:.2f}, {limite_superior:.2f}]\")\n",
    "    \n",
    "    if not outliers_info:\n",
    "        print(\"✓ No se detectaron outliers significativos\")\n",
    "    \n",
    "    return outliers_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "085fd9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_visualizaciones(df, info_variables):\n",
    "    \"\"\"Crea visualizaciones para el análisis exploratorio\"\"\"\n",
    "    \n",
    "    numericas = info_variables['numericas']\n",
    "    categoricas = info_variables['categoricas']\n",
    "    \n",
    "    # 1. Distribución de variables numéricas\n",
    "    if len(numericas) > 0:\n",
    "        n_cols = min(3, len(numericas))\n",
    "        n_rows = (len(numericas) + n_cols - 1) // n_cols\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "        axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "        \n",
    "        for idx, col in enumerate(numericas):\n",
    "            if idx < len(axes):\n",
    "                df[col].hist(bins=30, ax=axes[idx], edgecolor='black')\n",
    "                axes[idx].set_title(f'Distribución de {col}')\n",
    "                axes[idx].set_xlabel(col)\n",
    "                axes[idx].set_ylabel('Frecuencia')\n",
    "        \n",
    "        # Ocultar ejes vacíos\n",
    "        for idx in range(len(numericas), len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(CARPETA_RESULTADOS, 'distribucion_numericas.png'), dpi=300, bbox_inches='tight')\n",
    "        print(\"\\n✓ Gráfico guardado: distribucion_numericas.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    # 2. Boxplots para detección de outliers\n",
    "    if len(numericas) > 0:\n",
    "        n_cols = min(3, len(numericas))\n",
    "        n_rows = (len(numericas) + n_cols - 1) // n_cols\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "        axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "        \n",
    "        for idx, col in enumerate(numericas):\n",
    "            if idx < len(axes):\n",
    "                df.boxplot(column=col, ax=axes[idx])\n",
    "                axes[idx].set_title(f'Boxplot de {col}')\n",
    "                axes[idx].set_ylabel(col)\n",
    "        \n",
    "        for idx in range(len(numericas), len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(CARPETA_RESULTADOS, 'boxplots_outliers.png'), dpi=300, bbox_inches='tight')\n",
    "        print(\"✓ Gráfico guardado: boxplots_outliers.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    # 3. Matriz de correlación\n",
    "    if len(numericas) > 1:\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        correlation_matrix = df[numericas].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                    center=0, square=True, linewidths=1)\n",
    "        plt.title('Matriz de Correlación', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(CARPETA_RESULTADOS, 'matriz_correlacion.png'), dpi=300, bbox_inches='tight')\n",
    "        print(\"✓ Gráfico guardado: matriz_correlacion.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    # 4. Distribución de variables categóricas\n",
    "    if len(categoricas) > 0:\n",
    "        for col in categoricas[:5]:  # Primeras 5 categóricas\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            df[col].value_counts().head(10).plot(kind='bar', edgecolor='black')\n",
    "            plt.title(f'Distribución de {col}', fontsize=14, fontweight='bold')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Frecuencia')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(CARPETA_RESULTADOS, f'distribucion_{col}.png'), dpi=300, bbox_inches='tight')\n",
    "            print(f\"✓ Gráfico guardado: distribucion_{col}.png\")\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20db0a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingenieria_caracteristicas(df, info_variables):\n",
    "    \"\"\"\n",
    "    Crea nuevas variables útiles de forma controlada y coherente,\n",
    "    evitando generar variables redundantes o poco informativas.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"2. INGENIERÍA DE CARACTERÍSTICAS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df_nuevo = df.copy()\n",
    "    nuevas_variables = []\n",
    "\n",
    "    # A. Transformación de variables de fecha\n",
    "    fechas = info_variables.get('fechas', [])\n",
    "    for col in fechas:\n",
    "        if col not in df_nuevo.columns:\n",
    "            print(f\"⚠ Columna {col} no encontrada, se omite.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            if not np.issubdtype(df_nuevo[col].dtype, np.datetime64):\n",
    "                df_nuevo[col] = pd.to_datetime(df_nuevo[col], errors='coerce')\n",
    "            \n",
    "            if df_nuevo[col].isna().all():\n",
    "                print(f\"⚠ {col} no contiene fechas válidas, se omite.\")\n",
    "                continue\n",
    "            \n",
    "            # Extraer componentes útiles\n",
    "            for comp, func in zip(\n",
    "                ['año', 'mes', 'dia', 'dia_semana', 'trimestre'],\n",
    "                [lambda x: x.dt.year, lambda x: x.dt.month, lambda x: x.dt.day,\n",
    "                 lambda x: x.dt.dayofweek, lambda x: x.dt.quarter]\n",
    "            ):\n",
    "                nueva = f\"{col}_{comp}\"\n",
    "                df_nuevo[nueva] = func(df_nuevo[col])\n",
    "                nuevas_variables.append(nueva)\n",
    "\n",
    "            print(f\"✓ Características extraídas de {col}: Año, Mes, Día, Día de la semana, Trimestre\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ No se pudieron extraer características de {col}: {e}\")\n",
    "\n",
    "    # B. Binning de variables numéricas\n",
    "    numericas = info_variables.get('numericas', [])\n",
    "    for col in numericas[:3]:\n",
    "        if col not in df_nuevo.columns:\n",
    "            continue\n",
    "\n",
    "        valores_unicos = df_nuevo[col].nunique()\n",
    "        if valores_unicos < 5:\n",
    "            print(f\"⚠ {col} tiene pocos valores distintos ({valores_unicos}), no se binea.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df_nuevo[f'{col}_bin'] = pd.qcut(\n",
    "                df_nuevo[col],\n",
    "                q=4,\n",
    "                labels=['Bajo', 'Medio-Bajo', 'Medio-Alto', 'Alto'],\n",
    "                duplicates='drop'\n",
    "            )\n",
    "            nuevas_variables.append(f'{col}_bin')\n",
    "            print(f\"✓ Variable binned creada: {col}_bin (cuartiles)\")\n",
    "        except Exception:\n",
    "            print(f\"⚠ No se pudo crear bins para {col} (valores fuera de rango o constantes)\")\n",
    "\n",
    "    # C. Codificación de variables categóricas\n",
    "    categoricas = info_variables.get('categoricas', [])\n",
    "    print(\"\\n--- CODIFICACIÓN DE VARIABLES CATEGÓRICAS ---\")\n",
    "\n",
    "    for col in categoricas:\n",
    "        if col not in df_nuevo.columns:\n",
    "            continue\n",
    "\n",
    "        n_unique = df_nuevo[col].nunique(dropna=True)\n",
    "        if n_unique == 1:\n",
    "            print(f\"⚠ {col} tiene una sola categoría, se omite.\")\n",
    "            continue\n",
    "\n",
    "        if n_unique <= 10:\n",
    "            dummies = pd.get_dummies(df_nuevo[col], prefix=col, drop_first=True)\n",
    "            if dummies.shape[1] > 0:\n",
    "                df_nuevo = pd.concat([df_nuevo, dummies], axis=1)\n",
    "                nuevas_variables.extend(dummies.columns.tolist())\n",
    "                print(f\"✓ One-Hot Encoding aplicado a {col} ({n_unique} categorías)\")\n",
    "        else:\n",
    "            df_nuevo[f'{col}_encoded'] = pd.Categorical(df_nuevo[col]).codes\n",
    "            nuevas_variables.append(f'{col}_encoded')\n",
    "            print(f\"✓ Label Encoding aplicado a {col} ({n_unique} categorías)\")\n",
    "\n",
    "    # D. Interacciones entre variables numéricas\n",
    "    if len(numericas) >= 2:\n",
    "        print(\"\\n--- CREACIÓN DE VARIABLES DE INTERACCIÓN ---\")\n",
    "        col1, col2 = numericas[0], numericas[1]\n",
    "\n",
    "        if col1 in df_nuevo.columns and col2 in df_nuevo.columns:\n",
    "            # Solo crear si hay variabilidad\n",
    "            if df_nuevo[col1].std() > 0 and df_nuevo[col2].std() > 0:\n",
    "                df_nuevo[f'{col1}_x_{col2}'] = df_nuevo[col1] * df_nuevo[col2]\n",
    "                nuevas_variables.append(f'{col1}_x_{col2}')\n",
    "                print(f\"✓ Variable de interacción creada: {col1}_x_{col2}\")\n",
    "\n",
    "                df_nuevo[f'{col1}_div_{col2}'] = df_nuevo[col1] / (df_nuevo[col2] + 1e-6)\n",
    "                nuevas_variables.append(f'{col1}_div_{col2}')\n",
    "                print(f\"✓ Variable ratio creada: {col1}_div_{col2}\")\n",
    "            else:\n",
    "                print(f\"⚠ {col1} o {col2} tienen desviación cero, no se crean interacciones.\")\n",
    "\n",
    "    # E. Variables de agregación\n",
    "    if categoricas and numericas:\n",
    "        print(\"\\n--- VARIABLES DE AGREGACIÓN ---\")\n",
    "        cat_col = categoricas[0]\n",
    "        num_col = numericas[0]\n",
    "\n",
    "        if cat_col in df_nuevo.columns and num_col in df_nuevo.columns:\n",
    "            try:\n",
    "                df_nuevo[f'{num_col}_mean_by_{cat_col}'] = df_nuevo.groupby(cat_col)[num_col].transform('mean')\n",
    "                nuevas_variables.append(f'{num_col}_mean_by_{cat_col}')\n",
    "                print(f\"✓ Variable agregada: {num_col}_mean_by_{cat_col}\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠ No se pudo crear variable agregada: {e}\")\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RESUMEN: Se crearon {len(nuevas_variables)} nuevas características\")\n",
    "    print(f\"Dataset original: {df.shape[1]} columnas\")\n",
    "    print(f\"Dataset transformado: {df_nuevo.shape[1]} columnas\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    return df_nuevo, nuevas_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5168fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportar_resultados(df_original, df_transformado, info_variables, nuevas_vars):\n",
    "    \"\"\"Exporta resultados a CSV para generar el PDF\"\"\"\n",
    "    \n",
    "    # Guardar dataset transformado\n",
    "    df_transformado.to_csv(os.path.join(CARPETA_RESULTADOS, 'dataset_transformado.csv'), index=False)\n",
    "\n",
    "\n",
    "    print(\"\\n✓ Dataset transformado guardado: dataset_transformado.csv\")\n",
    "    \n",
    "    # Guardar resumen de análisis\n",
    "    with open(os.path.join(CARPETA_RESULTADOS, 'resumen_analisis.txt'), 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"RESUMEN DEL ANÁLISIS EXPLORATORIO DE DATOS\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"1. INFORMACIÓN GENERAL\\n\")\n",
    "        f.write(f\"   - Filas: {df_original.shape[0]}\\n\")\n",
    "        f.write(f\"   - Columnas originales: {df_original.shape[1]}\\n\")\n",
    "        f.write(f\"   - Columnas después de transformación: {df_transformado.shape[1]}\\n\\n\")\n",
    "        \n",
    "        f.write(\"2. TIPOS DE VARIABLES\\n\")\n",
    "        f.write(f\"   - Variables numéricas: {len(info_variables['numericas'])}\\n\")\n",
    "        f.write(f\"   - Variables categóricas: {len(info_variables['categoricas'])}\\n\")\n",
    "        f.write(f\"   - Variables de fecha: {len(info_variables['fechas'])}\\n\\n\")\n",
    "        \n",
    "        f.write(\"3. NUEVAS CARACTERÍSTICAS CREADAS\\n\")\n",
    "        f.write(f\"   - Total: {len(nuevas_vars)}\\n\")\n",
    "        for var in nuevas_vars[:20]:  # Primeras 20\n",
    "            f.write(f\"   - {var}\\n\")\n",
    "        if len(nuevas_vars) > 20:\n",
    "            f.write(f\"   ... y {len(nuevas_vars) - 20} más\\n\")\n",
    "    \n",
    "    print(\"✓ Resumen guardado: resumen_analisis.txt\")\n",
    "                                                                                                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a1f6bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_analisis():\n",
    "    \"\"\"Función principal que ejecuta todo el análisis\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ANÁLISIS EXPLORATORIO DE DATOS - ORACLE DATABASE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Conectar a Oracle\n",
    "    conn = conectar_oracle()\n",
    "    if conn is None:\n",
    "        return\n",
    "    query = \"SELECT * FROM VISTA_IA\"\n",
    "    # Cargar datos (personaliza tu query)\n",
    "    df = cargar_datos(conn, query)\n",
    "    \n",
    "    if df is None:\n",
    "        conn.close()\n",
    "        return\n",
    "    \n",
    "    # Cerrar conexión\n",
    "    conn.close()\n",
    "    \n",
    "    # Análisis descriptivo\n",
    "    info_vars = analisis_descriptivo(df)\n",
    "    \n",
    "    # Detección de outliers\n",
    "    if len(info_vars['numericas']) > 0:\n",
    "        detectar_outliers(df, info_vars['numericas'])\n",
    "    \n",
    "    # Crear visualizaciones\n",
    "    crear_visualizaciones(df, info_vars)\n",
    "    \n",
    "    # Ingeniería de características\n",
    "    df_transformado, nuevas_vars = ingenieria_caracteristicas(df, info_vars)\n",
    "    \n",
    "    # Exportar resultados\n",
    "    exportar_resultados(df, df_transformado, info_vars, nuevas_vars)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"✓ ANÁLISIS COMPLETADO\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nArchivos generados:\")\n",
    "    print(\"  - distribucion_numericas.png\")\n",
    "    print(\"  - boxplots_outliers.png\")\n",
    "    print(\"  - matriz_correlacion.png\")\n",
    "    print(\"  - distribucion_[variable].png (por cada categórica)\")\n",
    "    print(\"  - dataset_transformado.csv\")\n",
    "    print(\"  - resumen_analisis.txt\")\n",
    "    print(\"  - resumen_estadistico.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "030a42cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANÁLISIS EXPLORATORIO DE DATOS - ORACLE DATABASE\n",
      "================================================================================\n",
      "✓ Datos cargados: 21210 filas, 13 columnas\n",
      "\n",
      "================================================================================\n",
      "1. ANÁLISIS DESCRIPTIVO INICIAL\n",
      "================================================================================\n",
      "\n",
      "--- INFORMACIÓN GENERAL ---\n",
      "Dimensiones: 21210 filas × 13 columnas\n",
      "Memoria utilizada: 6.71 MB\n",
      "\n",
      "--- TIPOS DE DATOS ---\n",
      "int64     9\n",
      "object    4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Variables numéricas (9): ['SEXO', 'ESTANCIA_DÍAS', 'NIVEL_SEVERIDAD_APR', 'RIESGO_MORTALIDAD_APR', 'EDAD', 'CONTINUIDAD_ASISTENCIAL', 'INGRESO_EN_UCI', 'EDAD_EN_INGRESO', 'COSTE_APR']\n",
      "Variables categóricas (4): ['Diagnóstico Principal', 'Diagnóstico 2', 'Diagnóstico 3', 'COMUNIDAD_AUTÓNOMA']\n",
      "Variables de fecha (0): []\n",
      "\n",
      "--- VALORES NULOS Y DESCONOCIDOS ---\n",
      "     Variable  Valores Nulos  % Nulos\n",
      "Diagnóstico 3           6150    29.00\n",
      "Diagnóstico 2           2604    12.28\n",
      "\n",
      "--- ESTADÍSTICAS DESCRIPTIVAS (Variables Numéricas) ---\n",
      "           SEXO  ESTANCIA_DÍAS  NIVEL_SEVERIDAD_APR  RIESGO_MORTALIDAD_APR  \\\n",
      "count  21210.00       21210.00             21210.00               21210.00   \n",
      "mean       1.45          15.46                 1.54                   1.06   \n",
      "std        0.56          19.88                 0.58                   0.28   \n",
      "min        1.00           0.00                 1.00                   1.00   \n",
      "25%        1.00           5.00                 1.00                   1.00   \n",
      "50%        1.00          11.00                 1.00                   1.00   \n",
      "75%        2.00          19.00                 2.00                   1.00   \n",
      "max        9.00         814.00                 4.00                   4.00   \n",
      "\n",
      "           EDAD  CONTINUIDAD_ASISTENCIAL  INGRESO_EN_UCI  EDAD_EN_INGRESO  \\\n",
      "count  21210.00                 21210.00        21210.00         21210.00   \n",
      "mean      43.64                     8.41            2.12            43.68   \n",
      "std       14.11                     2.08            0.93            14.12   \n",
      "min        0.00                     1.00            1.00             0.00   \n",
      "25%       34.00                     9.00            2.00            34.00   \n",
      "50%       44.00                     9.00            2.00            44.00   \n",
      "75%       53.00                     9.00            2.00            53.00   \n",
      "max       96.00                     9.00            9.00            96.00   \n",
      "\n",
      "       COSTE_APR  \n",
      "count   21210.00  \n",
      "mean     5453.11  \n",
      "std      1561.75  \n",
      "min      1496.00  \n",
      "25%      4228.00  \n",
      "50%      5988.00  \n",
      "75%      6319.00  \n",
      "max     70601.00  \n",
      "\n",
      "--- MEDIA, VARIANZA Y DESVIACIÓN TÍPICA ---\n",
      "                           Media    Varianza  Desviación Típica\n",
      "SEXO                        1.45        0.31               0.56\n",
      "ESTANCIA_DÍAS              15.46      395.28              19.88\n",
      "NIVEL_SEVERIDAD_APR         1.54        0.34               0.58\n",
      "RIESGO_MORTALIDAD_APR       1.06        0.08               0.28\n",
      "EDAD                       43.64      199.02              14.11\n",
      "CONTINUIDAD_ASISTENCIAL     8.41        4.34               2.08\n",
      "INGRESO_EN_UCI              2.12        0.86               0.93\n",
      "EDAD_EN_INGRESO            43.68      199.33              14.12\n",
      "COSTE_APR                5453.11  2439058.06            1561.75\n",
      "✓ Resumen estadístico guardado: resultado_analisis/resumen_estadistico.csv\n",
      "\n",
      "--- ANÁLISIS DE VARIABLES CATEGÓRICAS ---\n",
      "\n",
      "Diagnóstico Principal:\n",
      "  Valores únicos: 263\n",
      "  Top 5 valores más frecuentes:\n",
      "Diagnóstico Principal\n",
      "F20.0    4573\n",
      "F60.3    1372\n",
      "F29       909\n",
      "F31.2     877\n",
      "F25.0     820\n",
      "\n",
      "Diagnóstico 2:\n",
      "  Valores únicos: 1586\n",
      "  Top 5 valores más frecuentes:\n",
      "Diagnóstico 2\n",
      "F17.210    989\n",
      "R45.851    890\n",
      "Z81.8      804\n",
      "I10        681\n",
      "F12.10     584\n",
      "\n",
      "Diagnóstico 3:\n",
      "  Valores únicos: 1539\n",
      "  Top 5 valores más frecuentes:\n",
      "Diagnóstico 3\n",
      "F17.210    1127\n",
      "Z81.8       643\n",
      "I10         579\n",
      "F12.10      520\n",
      "F10.10      502\n",
      "\n",
      "COMUNIDAD_AUTÓNOMA:\n",
      "  Valores únicos: 2\n",
      "  Top 5 valores más frecuentes:\n",
      "COMUNIDAD_AUTÓNOMA\n",
      "ANDALUCÍA    20034\n",
      "LA RIOJA      1176\n",
      "\n",
      "--- DETECCIÓN DE OUTLIERS ---\n",
      "\n",
      "SEXO:\n",
      "  Outliers (IQR): 25 (0.12%)\n",
      "  Outliers (Z-score > 3): 25\n",
      "  Rango normal: [-0.50, 3.50]\n",
      "\n",
      "ESTANCIA_DÍAS:\n",
      "  Outliers (IQR): 1229 (5.79%)\n",
      "  Outliers (Z-score > 3): 262\n",
      "  Rango normal: [-16.00, 40.00]\n",
      "\n",
      "NIVEL_SEVERIDAD_APR:\n",
      "  Outliers (IQR): 149 (0.7%)\n",
      "  Outliers (Z-score > 3): 149\n",
      "  Rango normal: [-0.50, 3.50]\n",
      "\n",
      "RIESGO_MORTALIDAD_APR:\n",
      "  Outliers (IQR): 1013 (4.78%)\n",
      "  Outliers (Z-score > 3): 1013\n",
      "  Rango normal: [1.00, 1.00]\n",
      "\n",
      "EDAD:\n",
      "  Outliers (IQR): 149 (0.7%)\n",
      "  Outliers (Z-score > 3): 50\n",
      "  Rango normal: [5.50, 81.50]\n",
      "\n",
      "CONTINUIDAD_ASISTENCIAL:\n",
      "  Outliers (IQR): 1609 (7.59%)\n",
      "  Outliers (Z-score > 3): 1546\n",
      "  Rango normal: [9.00, 9.00]\n",
      "\n",
      "INGRESO_EN_UCI:\n",
      "  Outliers (IQR): 477 (2.25%)\n",
      "  Outliers (Z-score > 3): 377\n",
      "  Rango normal: [2.00, 2.00]\n",
      "\n",
      "EDAD_EN_INGRESO:\n",
      "  Outliers (IQR): 149 (0.7%)\n",
      "  Outliers (Z-score > 3): 39\n",
      "  Rango normal: [5.50, 81.50]\n",
      "\n",
      "COSTE_APR:\n",
      "  Outliers (IQR): 191 (0.9%)\n",
      "  Outliers (Z-score > 3): 157\n",
      "  Rango normal: [1091.50, 9455.50]\n",
      "\n",
      "✓ Gráfico guardado: distribucion_numericas.png\n",
      "✓ Gráfico guardado: boxplots_outliers.png\n",
      "✓ Gráfico guardado: matriz_correlacion.png\n",
      "✓ Gráfico guardado: distribucion_Diagnóstico Principal.png\n",
      "✓ Gráfico guardado: distribucion_Diagnóstico 2.png\n",
      "✓ Gráfico guardado: distribucion_Diagnóstico 3.png\n",
      "✓ Gráfico guardado: distribucion_COMUNIDAD_AUTÓNOMA.png\n",
      "\n",
      "================================================================================\n",
      "2. INGENIERÍA DE CARACTERÍSTICAS\n",
      "================================================================================\n",
      "⚠ SEXO tiene pocos valores distintos (3), no se binea.\n",
      "✓ Variable binned creada: ESTANCIA_DÍAS_bin (cuartiles)\n",
      "⚠ NIVEL_SEVERIDAD_APR tiene pocos valores distintos (4), no se binea.\n",
      "\n",
      "--- CODIFICACIÓN DE VARIABLES CATEGÓRICAS ---\n",
      "✓ Label Encoding aplicado a Diagnóstico Principal (263 categorías)\n",
      "✓ Label Encoding aplicado a Diagnóstico 2 (1586 categorías)\n",
      "✓ Label Encoding aplicado a Diagnóstico 3 (1539 categorías)\n",
      "✓ One-Hot Encoding aplicado a COMUNIDAD_AUTÓNOMA (2 categorías)\n",
      "\n",
      "--- CREACIÓN DE VARIABLES DE INTERACCIÓN ---\n",
      "✓ Variable de interacción creada: SEXO_x_ESTANCIA_DÍAS\n",
      "✓ Variable ratio creada: SEXO_div_ESTANCIA_DÍAS\n",
      "\n",
      "--- VARIABLES DE AGREGACIÓN ---\n",
      "✓ Variable agregada: SEXO_mean_by_Diagnóstico Principal\n",
      "\n",
      "================================================================================\n",
      "RESUMEN: Se crearon 8 nuevas características\n",
      "Dataset original: 13 columnas\n",
      "Dataset transformado: 21 columnas\n",
      "================================================================================\n",
      "\n",
      "✓ Dataset transformado guardado: dataset_transformado.csv\n",
      "✓ Resumen guardado: resumen_analisis.txt\n",
      "\n",
      "================================================================================\n",
      "✓ ANÁLISIS COMPLETADO\n",
      "================================================================================\n",
      "\n",
      "Archivos generados:\n",
      "  - distribucion_numericas.png\n",
      "  - boxplots_outliers.png\n",
      "  - matriz_correlacion.png\n",
      "  - distribucion_[variable].png (por cada categórica)\n",
      "  - dataset_transformado.csv\n",
      "  - resumen_analisis.txt\n",
      "  - resumen_estadistico.csv\n"
     ]
    }
   ],
   "source": [
    "ejecutar_analisis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
